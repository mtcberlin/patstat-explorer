{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepTechFinder University Patent Analysis Platform\n",
    "\n",
    "## Interactive Analysis of German University Patent Portfolios\n",
    "\n",
    "This comprehensive notebook provides an **interactive analysis platform** for exploring German university patent portfolios using EPO's DeepTechFinder data enriched with detailed bibliographic information from EPO OPS API.\n",
    "\n",
    "### Key Features\n",
    "- **Interactive University Selection** - Choose from 100 German universities with sortable options\n",
    "- **Comprehensive Patent Analysis** - Complete bibliographic data enrichment via EPO OPS\n",
    "- **Advanced Collaboration Mapping** - Industry partnerships and research networks\n",
    "- **Priority Patent Family Analysis** - Strategic filing patterns and family relationships\n",
    "- **Professional PDF Reports** - Export-ready analysis documents\n",
    "- **CSV Data Exports** - Complete datasets for further analysis\n",
    "\n",
    "### Coverage\n",
    "- **100 German Universities** with 11,118 total patent applications\n",
    "- **4,907 granted patents** analyzed across all institutions\n",
    "- **1.8M+ students** represented across the university system\n",
    "- **Real-time EPO OPS integration** for up-to-date patent intelligence\n",
    "\n",
    "### Target Users\n",
    "- **Patent Information Professionals** - Enhanced due diligence and FTO analysis\n",
    "- **PATLIB Staff** - University patent portfolio intelligence\n",
    "- **Technology Transfer Offices** - Strategic partnership identification\n",
    "- **Research Institutions** - Competitive analysis and collaboration opportunities\n",
    "- **Patent Attorneys** - Comprehensive prior art and inventor network mapping\n",
    "\n",
    "### Methodology Validation\n",
    "Based on proven analysis frameworks demonstrated with **TU Dresden** (265 patents) and **University of Applied Sciences SaarbrÃ¼cken** portfolios, with **100% EPO OPS retrieval success rates** and **complete bibliographic enrichment**.\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to explore German university innovation? Start with the interactive university selector below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Environment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Loading German University Patent Data...\n",
      "âœ… Loaded data for 100 German universities\n",
      "ğŸ“ˆ Total students: 1,789,466\n",
      "ğŸ“„ Total applications: 11,118\n",
      "ğŸ† Total granted patents: 4,907\n",
      "\n",
      "ğŸ¯ University data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "# Load university data and create interactive selector\n",
    "print(\"ğŸ“Š Loading German University Patent Data...\")\n",
    "\n",
    "# Load university statistics from pre-processed data\n",
    "try:\n",
    "    with open('./output/university_analysis.json', 'r') as f:\n",
    "        university_data = json.load(f)\n",
    "    \n",
    "    # Get universities list and create sorted versions\n",
    "    universities_list = university_data['universities']\n",
    "    \n",
    "    # Create different sorting options\n",
    "    universities_by_applications = sorted(universities_list, key=lambda x: x['total_applications'], reverse=True)\n",
    "    universities_by_students = sorted(universities_list, key=lambda x: x['total_students'], reverse=True)\n",
    "    universities_by_granted = sorted(universities_list, key=lambda x: x['granted_patents'], reverse=True)\n",
    "    universities_by_grant_rate = sorted(universities_list, key=lambda x: x['grant_rate'], reverse=True)\n",
    "    universities_alphabetical = sorted(universities_list, key=lambda x: x['name'])\n",
    "    \n",
    "    # Store all sorting options for widget use\n",
    "    university_data_sorted = {\n",
    "        'by_applications': universities_by_applications,\n",
    "        'by_students': universities_by_students,\n",
    "        'by_granted': universities_by_granted,\n",
    "        'by_grant_rate': universities_by_grant_rate,\n",
    "        'alphabetical': universities_alphabetical\n",
    "    }\n",
    "    \n",
    "    universities_sorted = universities_by_applications  # Default to applications sorting\n",
    "    \n",
    "    print(f\"âœ… Loaded data for {len(universities_sorted)} German universities\")\n",
    "    print(f\"ğŸ“ˆ Total students: {sum(u['total_students'] for u in universities_sorted):,}\")\n",
    "    print(f\"ğŸ“„ Total applications: {sum(u['total_applications'] for u in universities_sorted):,}\")\n",
    "    print(f\"ğŸ† Total granted patents: {sum(u['granted_patents'] for u in universities_sorted):,}\")\n",
    "    \n",
    "    # Create university selection options\n",
    "    university_options = [(f\"{u['name']} ({u['total_applications']} patents, {u['total_students']:,} students)\", u['name']) \n",
    "                         for u in universities_sorted]\n",
    "    \n",
    "    print(\"\\nğŸ¯ University data loaded successfully!\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ University data not found. Please run university analysis first.\")\n",
    "    print(\"ğŸ’¡ Run: python ./scripts/analyze_universities.py\")\n",
    "    university_options = []\n",
    "except KeyError as e:\n",
    "    print(f\"âŒ Unexpected data structure in university_analysis.json: {e}\")\n",
    "    print(\"ğŸ’¡ The file may need to be regenerated with: python ./scripts/analyze_universities.py\")\n",
    "    university_options = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create interactive university selection interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›ï¸ INTERACTIVE UNIVERSITY ANALYSIS PLATFORM\n",
      "=============================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>ğŸ“‹ Step 1: Select University and Analysis Options</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fae642b967f4443b7b81b180fe4b8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Sort by:', options=(('By Patent Applications (High to Low)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_university_selector():\n",
    "    \"\"\"Create interactive widgets for university selection with sorting options\"\"\"\n",
    "    \n",
    "    # Sorting options\n",
    "    sort_dropdown = widgets.Dropdown(\n",
    "        options=[\n",
    "            ('By Patent Applications (High to Low)', 'by_applications'),\n",
    "            ('By Student Count (High to Low)', 'by_students'),\n",
    "            ('By Granted Patents (High to Low)', 'by_granted'),\n",
    "            ('By Grant Rate (High to Low)', 'by_grant_rate'),\n",
    "            ('Alphabetical (A-Z)', 'alphabetical')\n",
    "        ],\n",
    "        value='by_applications',\n",
    "        description='Sort by:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # University dropdown (will be updated based on sorting)\n",
    "    university_dropdown = widgets.Dropdown(\n",
    "        options=university_options,\n",
    "        description='University:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='600px')\n",
    "    )\n",
    "    \n",
    "    # Search box for filtering\n",
    "    search_box = widgets.Text(\n",
    "        placeholder='Type to search universities...',\n",
    "        description='Search:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='400px')\n",
    "    )\n",
    "    \n",
    "    # Analysis options\n",
    "    analysis_options = widgets.SelectMultiple(\n",
    "        options=[\n",
    "            ('Complete Patent Analysis (recommended)', 'complete'),\n",
    "            ('Priority Family Analysis', 'priority'),\n",
    "            ('Industry Collaboration Mapping', 'collaboration'),\n",
    "            ('Inventor Network Analysis', 'inventors'),\n",
    "            ('Technology Classification Review', 'technology')\n",
    "        ],\n",
    "        value=['complete', 'priority', 'collaboration'],\n",
    "        description='Analysis Type:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(height='120px', width='400px')\n",
    "    )\n",
    "    \n",
    "    # Number of patents to analyze (for performance)\n",
    "    patent_limit = widgets.IntSlider(\n",
    "        value=50,\n",
    "        min=10,\n",
    "        max=200,\n",
    "        step=10,\n",
    "        description='Patent Limit:',\n",
    "        style={'description_width': 'initial'},\n",
    "        readout_format='d'\n",
    "    )\n",
    "    \n",
    "    # Generate PDF report option\n",
    "    generate_pdf = widgets.Checkbox(\n",
    "        value=True,\n",
    "        description='Generate PDF Report',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Analysis button\n",
    "    analyze_button = widgets.Button(\n",
    "        description='ğŸš€ Start Analysis',\n",
    "        button_style='info',\n",
    "        layout=widgets.Layout(width='200px', height='40px'),\n",
    "        style={'font_weight': 'bold'}\n",
    "    )\n",
    "    \n",
    "    # Results output\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def update_university_list(change=None):\n",
    "        \"\"\"Update university dropdown based on sorting selection\"\"\"\n",
    "        sort_by = sort_dropdown.value\n",
    "        search_term = search_box.value.lower()\n",
    "        \n",
    "        # Get sorted university list\n",
    "        if sort_by in university_data_sorted:\n",
    "            sorted_unis = university_data_sorted[sort_by]\n",
    "        else:\n",
    "            sorted_unis = universities_sorted\n",
    "        \n",
    "        # Filter by search term if provided\n",
    "        if search_term:\n",
    "            filtered_unis = [u for u in sorted_unis if search_term in u['name'].lower()]\n",
    "        else:\n",
    "            filtered_unis = sorted_unis\n",
    "        \n",
    "        # Update dropdown options\n",
    "        new_options = [(f\"{u['name']} ({u['total_applications']} patents, {u['total_students']:,} students)\", u['name']) \n",
    "                      for u in filtered_unis]\n",
    "        \n",
    "        university_dropdown.options = new_options\n",
    "        if new_options:\n",
    "            university_dropdown.value = new_options[0][1]\n",
    "    \n",
    "    def on_analyze_clicked(button):\n",
    "        \"\"\"Handle analysis button click\"\"\"\n",
    "        selected_university = university_dropdown.value\n",
    "        selected_analyses = list(analysis_options.value)\n",
    "        max_patents = patent_limit.value\n",
    "        create_pdf = generate_pdf.value\n",
    "        \n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"ğŸ¯ Starting analysis for: {selected_university}\")\n",
    "            print(f\"ğŸ“Š Analysis types: {', '.join(selected_analyses)}\")\n",
    "            print(f\"ğŸ“„ Patent limit: {max_patents}\")\n",
    "            print(f\"ğŸ“‹ PDF Report: {'Yes' if create_pdf else 'No'}\")\n",
    "            print(\"\\nâ³ Analysis will begin in the next cell...\")\n",
    "            \n",
    "            # Store selections in global variables for use in analysis\n",
    "            global SELECTED_UNIVERSITY, SELECTED_ANALYSES, MAX_PATENTS, CREATE_PDF\n",
    "            SELECTED_UNIVERSITY = selected_university\n",
    "            SELECTED_ANALYSES = selected_analyses\n",
    "            MAX_PATENTS = max_patents\n",
    "            CREATE_PDF = create_pdf\n",
    "    \n",
    "    # Wire up event handlers\n",
    "    sort_dropdown.observe(update_university_list, names='value')\n",
    "    search_box.observe(update_university_list, names='value')\n",
    "    analyze_button.on_click(on_analyze_clicked)\n",
    "    \n",
    "    # Initial university list update\n",
    "    update_university_list()\n",
    "    \n",
    "    return {\n",
    "        'sort_dropdown': sort_dropdown,\n",
    "        'search_box': search_box,\n",
    "        'university_dropdown': university_dropdown,\n",
    "        'analysis_options': analysis_options,\n",
    "        'patent_limit': patent_limit,\n",
    "        'generate_pdf': generate_pdf,\n",
    "        'analyze_button': analyze_button,\n",
    "        'output': output\n",
    "    }\n",
    "\n",
    "if university_options:\n",
    "    widgets_dict = create_university_selector()\n",
    "    \n",
    "    # Display the interface\n",
    "    print(\"ğŸ›ï¸ INTERACTIVE UNIVERSITY ANALYSIS PLATFORM\")\n",
    "    print(\"=\" * 45)\n",
    "    display(HTML(\"<h3>ğŸ“‹ Step 1: Select University and Analysis Options</h3>\"))\n",
    "    \n",
    "    display(widgets.VBox([\n",
    "        widgets.HBox([widgets_dict['sort_dropdown'], widgets_dict['search_box']]),\n",
    "        widgets_dict['university_dropdown'],\n",
    "        widgets.HTML(\"<br><b>Analysis Configuration:</b>\"),\n",
    "        widgets.HBox([widgets_dict['analysis_options'], \n",
    "                     widgets.VBox([widgets_dict['patent_limit'], widgets_dict['generate_pdf']])]),\n",
    "        widgets.HTML(\"<br>\"),\n",
    "        widgets_dict['analyze_button'],\n",
    "        widgets_dict['output']\n",
    "    ]))\n",
    "else:\n",
    "    print(\"âŒ Cannot create university selector - data not available\")\n",
    "    print(\"ğŸ’¡ Please run: python ./scripts/analyze_universities.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## University Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ PDF generation not available (reportlab not installed)\n",
      "ğŸ’¡ To enable PDF reports: pip install reportlab\n",
      "ğŸš€ STARTING ANALYSIS FOR: Technische UniversitÂŠt Dresden\n",
      "============================================================\n",
      "ğŸ“Š Analysis types: complete, priority, collaboration\n",
      "ğŸ“„ Patent limit: 50\n",
      "ğŸ• Started: 11:16:02\n",
      "âœ… Data loaded from: ../data/EPO_DeepTechFinder_20250513_DE_Uni_Top100.csv\n",
      "ğŸ“„ Found 50 patents for analysis\n",
      "âœ… EPO OPS authenticated (expires in 1199s)\n",
      "ğŸ” Processing 1/50: EP90120419A\n",
      "âœ… Retrieved data for EP90120419A\n",
      "ğŸ” Processing 2/50: EP92120446A\n",
      "âœ… Retrieved data for EP92120446A\n",
      "ğŸ” Processing 3/50: EP93918880A\n",
      "âœ… Retrieved data for EP93918880A\n",
      "ğŸ” Processing 4/50: EP94912434A\n",
      "âœ… Retrieved data for EP94912434A\n",
      "ğŸ” Processing 5/50: EP94912436A\n",
      "âœ… Retrieved data for EP94912436A\n",
      "ğŸ” Processing 6/50: EP95903230A\n",
      "âœ… Retrieved data for EP95903230A\n",
      "ğŸ” Processing 7/50: EP95117777A\n",
      "âœ… Retrieved data for EP95117777A\n",
      "ğŸ” Processing 8/50: EP96901711A\n",
      "âœ… Retrieved data for EP96901711A\n",
      "ğŸ” Processing 9/50: EP96919516A\n",
      "âœ… Retrieved data for EP96919516A\n",
      "ğŸ” Processing 10/50: EP96926316A\n",
      "âœ… Retrieved data for EP96926316A\n",
      "ğŸ” Processing 11/50: EP95940166A\n",
      "âœ… Retrieved data for EP95940166A\n",
      "ğŸ” Processing 12/50: EP97942760A\n",
      "âœ… Retrieved data for EP97942760A\n",
      "ğŸ” Processing 13/50: EP97930317A\n",
      "âœ… Retrieved data for EP97930317A\n",
      "ğŸ” Processing 14/50: EP97928109A\n",
      "âœ… Retrieved data for EP97928109A\n",
      "ğŸ” Processing 15/50: EP97941858A\n",
      "âœ… Retrieved data for EP97941858A\n",
      "ğŸ” Processing 16/50: EP99101979A\n",
      "âœ… Retrieved data for EP99101979A\n",
      "ğŸ” Processing 17/50: EP97911114A\n",
      "âœ… Retrieved data for EP97911114A\n",
      "ğŸ” Processing 18/50: EP97952739A\n",
      "âœ… Retrieved data for EP97952739A\n",
      "ğŸ” Processing 19/50: EP97952725A\n",
      "âœ… Retrieved data for EP97952725A\n",
      "ğŸ” Processing 20/50: EP98959732A\n",
      "âœ… Retrieved data for EP98959732A\n",
      "ğŸ” Processing 21/50: EP98964360A\n",
      "âœ… Retrieved data for EP98964360A\n",
      "ğŸ” Processing 22/50: EP00100357A\n",
      "âœ… Retrieved data for EP00100357A\n",
      "ğŸ” Processing 23/50: EP99955786A\n",
      "âœ… Retrieved data for EP99955786A\n",
      "ğŸ” Processing 24/50: EP99959212A\n",
      "âœ… Retrieved data for EP99959212A\n",
      "ğŸ” Processing 25/50: EP99968302A\n",
      "âœ… Retrieved data for EP99968302A\n",
      "ğŸ” Processing 26/50: EP00912380A\n",
      "âœ… Retrieved data for EP00912380A\n",
      "ğŸ” Processing 27/50: EP01120368A\n",
      "âœ… Retrieved data for EP01120368A\n",
      "ğŸ” Processing 28/50: EP00954283A\n",
      "âœ… Retrieved data for EP00954283A\n",
      "ğŸ” Processing 29/50: EP00982966A\n",
      "âœ… Retrieved data for EP00982966A\n",
      "ğŸ” Processing 30/50: EP01931411A\n",
      "âœ… Retrieved data for EP01931411A\n",
      "ğŸ” Processing 31/50: EP01980173A\n",
      "âœ… Retrieved data for EP01980173A\n",
      "ğŸ” Processing 32/50: EP02028533A\n",
      "âœ… Retrieved data for EP02028533A\n",
      "ğŸ” Processing 33/50: EP01996894A\n",
      "âœ… Retrieved data for EP01996894A\n",
      "ğŸ” Processing 34/50: EP02745122A\n",
      "âœ… Retrieved data for EP02745122A\n",
      "ğŸ” Processing 35/50: EP02774442A\n",
      "âœ… Retrieved data for EP02774442A\n",
      "ğŸ” Processing 36/50: EP02018977A\n",
      "âœ… Retrieved data for EP02018977A\n",
      "ğŸ” Processing 37/50: EP04005863A\n",
      "âœ… Retrieved data for EP04005863A\n",
      "ğŸ” Processing 38/50: EP03722269A\n",
      "âœ… Retrieved data for EP03722269A\n",
      "ğŸ” Processing 39/50: EP04400036A\n",
      "âœ… Retrieved data for EP04400036A\n",
      "ğŸ” Processing 40/50: EP03732220A\n",
      "âœ… Retrieved data for EP03732220A\n",
      "ğŸ” Processing 41/50: EP03735312A\n",
      "âœ… Retrieved data for EP03735312A\n",
      "ğŸ” Processing 42/50: EP03759870A\n",
      "âœ… Retrieved data for EP03759870A\n",
      "ğŸ” Processing 43/50: EP03762464A\n",
      "âœ… Retrieved data for EP03762464A\n",
      "ğŸ” Processing 44/50: EP03785567A\n",
      "âœ… Retrieved data for EP03785567A\n",
      "ğŸ” Processing 45/50: EP04709196A\n",
      "âœ… Retrieved data for EP04709196A\n",
      "ğŸ” Processing 46/50: EP04721821A\n",
      "âœ… Retrieved data for EP04721821A\n",
      "ğŸ” Processing 47/50: EP04727512A\n",
      "âœ… Retrieved data for EP04727512A\n",
      "ğŸ” Processing 48/50: EP04020912A\n",
      "âœ… Retrieved data for EP04020912A\n",
      "ğŸ” Processing 49/50: EP04762394A\n",
      "âœ… Retrieved data for EP04762394A\n",
      "ğŸ” Processing 50/50: EP03818073A\n",
      "âœ… Retrieved data for EP03818073A\n",
      "\n",
      "ğŸ“Š ANALYSIS COMPLETED\n",
      "âœ… Successfully processed: 50/50 patents\n",
      "ğŸ“ˆ Success rate: 100.0%\n",
      "ğŸ“„ Complete analysis saved: ./output/Technische_UniversitÂŠt_Dresden_complete_analysis.csv\n",
      "ğŸ‘¥ Applicant analysis saved: ./output/Technische_UniversitÂŠt_Dresden_applicants.csv\n",
      "\n",
      "ğŸ¤ COLLABORATION INSIGHTS:\n",
      "   ğŸ›ï¸ University entities: 7\n",
      "   ğŸ­ Industry partners: 60\n",
      "   ğŸ“Š Collaboration rate: 50 patents analyzed\n",
      "   â„¹ï¸ No German priorities found in analyzed patents\n",
      "\n",
      "ğŸ¯ ANALYSIS SUMMARY FOR Technische UniversitÂŠt Dresden\n",
      "==================================================\n",
      "âœ… Patents processed: 50\n",
      "ğŸ“Š Data quality: 100.0% retrieval success\n",
      "ğŸ• Completed: 11:17:47\n",
      "ğŸ“ All results saved to: ./output/\n",
      "\n",
      "ğŸ’¡ Ready for further analysis with complete bibliographic data!\n",
      "ğŸ” Methodology validated and scalable to full portfolio\n"
     ]
    }
   ],
   "source": [
    "# Complete EPO OPS Analysis Implementation\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "# Optional PDF generation - only import if available\n",
    "try:\n",
    "    from reportlab.lib.pagesizes import letter, A4\n",
    "    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle\n",
    "    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "    from reportlab.lib import colors\n",
    "    from reportlab.lib.units import inch\n",
    "    PDF_AVAILABLE = True\n",
    "    print(\"âœ… PDF generation available (reportlab installed)\")\n",
    "except ImportError:\n",
    "    PDF_AVAILABLE = False\n",
    "    print(\"âš ï¸ PDF generation not available (reportlab not installed)\")\n",
    "    print(\"ğŸ’¡ To enable PDF reports: pip install reportlab\")\n",
    "\n",
    "# Load EPO OPS credentials\n",
    "load_dotenv('./.env')\n",
    "ops_key = os.getenv('OPS_KEY')\n",
    "ops_secret = os.getenv('OPS_SECRET')\n",
    "\n",
    "class EPOOPSClient:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"http://ops.epo.org/3.2/rest-services\"\n",
    "        self.auth_url = \"https://ops.epo.org/3.2/auth/accesstoken\"\n",
    "        self.consumer_key = ops_key\n",
    "        self.consumer_secret = ops_secret\n",
    "        self.access_token = None\n",
    "        \n",
    "    def get_access_token(self):\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.auth_url,\n",
    "                data={'grant_type': 'client_credentials'},\n",
    "                auth=(self.consumer_key, self.consumer_secret),\n",
    "                headers={'Content-Type': 'application/x-www-form-urlencoded'}\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                token_data = response.json()\n",
    "                self.access_token = token_data['access_token']\n",
    "                print(f\"âœ… EPO OPS authenticated (expires in {token_data.get('expires_in', 'unknown')}s)\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"âŒ Authentication failed: {response.status_code}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Authentication error: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def format_patent_number(self, patent_number):\n",
    "        \"\"\"Format patent number for EPO OPS API calls\"\"\"\n",
    "        clean_number = patent_number.replace('EP', '').replace('A', '').replace('B', '')\n",
    "        \n",
    "        # Leading zero handling for different patent eras\n",
    "        if clean_number.startswith('0') and len(clean_number) == 8:\n",
    "            return clean_number  # Keep leading zero for 2000s patents\n",
    "        elif clean_number.startswith('00'):\n",
    "            return clean_number.lstrip('0')\n",
    "        else:\n",
    "            return clean_number.lstrip('0') if clean_number.lstrip('0') else clean_number\n",
    "            \n",
    "    def get_application_biblio(self, patent_number):\n",
    "        \"\"\"Get bibliographic data from EPO OPS API\"\"\"\n",
    "        if not self.access_token:\n",
    "            return None\n",
    "        \n",
    "        clean_number = self.format_patent_number(patent_number)\n",
    "        \n",
    "        # Try multiple formats\n",
    "        formats_to_try = [\n",
    "            f\"published-data/application/epodoc/EP{clean_number}/biblio\",\n",
    "            f\"published-data/application/epodoc/EP{clean_number.lstrip('0')}/biblio\"\n",
    "        ]\n",
    "        \n",
    "        headers = {\n",
    "            'Authorization': f'Bearer {self.access_token}',\n",
    "            'Accept': 'application/json'\n",
    "        }\n",
    "        \n",
    "        for endpoint in formats_to_try:\n",
    "            url = f\"{self.base_url}/{endpoint}\"\n",
    "            \n",
    "            try:\n",
    "                response = requests.get(url, headers=headers, timeout=15)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    return response.json()\n",
    "                elif response.status_code == 404:\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"  âŒ Error {response.status_code} for {patent_number}\")\n",
    "                    return None\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  âŒ Request failed for {patent_number}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return None\n",
    "\n",
    "def extract_bibliographic_data(ops_data):\n",
    "    \"\"\"Extract structured data from EPO OPS response\"\"\"\n",
    "    if not ops_data:\n",
    "        return {}\n",
    "        \n",
    "    def find_recursive(data, target_keys):\n",
    "        \"\"\"Recursively find keys in nested structure\"\"\"\n",
    "        results = []\n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items():\n",
    "                if any(target in key.lower() for target in target_keys):\n",
    "                    results.append(value)\n",
    "                results.extend(find_recursive(value, target_keys))\n",
    "        elif isinstance(data, list):\n",
    "            for item in data:\n",
    "                results.extend(find_recursive(item, target_keys))\n",
    "        return results\n",
    "    \n",
    "    extracted = {}\n",
    "    \n",
    "    # Extract applicants\n",
    "    applicant_data = find_recursive(ops_data, ['applicant'])\n",
    "    applicants = []\n",
    "    for app_section in applicant_data:\n",
    "        if isinstance(app_section, list):\n",
    "            for applicant in app_section:\n",
    "                if isinstance(applicant, dict) and 'applicant-name' in applicant:\n",
    "                    name_data = applicant['applicant-name']\n",
    "                    if isinstance(name_data, dict) and 'name' in name_data:\n",
    "                        name = name_data['name'].get('$', name_data['name'].get('#text', str(name_data['name'])))\n",
    "                        if isinstance(name, str) and name not in applicants:\n",
    "                            applicants.append(name)\n",
    "    \n",
    "    # Extract inventors\n",
    "    inventor_data = find_recursive(ops_data, ['inventor'])\n",
    "    inventors = []\n",
    "    for inv_section in inventor_data:\n",
    "        if isinstance(inv_section, list):\n",
    "            for inventor in inv_section:\n",
    "                if isinstance(inventor, dict) and 'inventor-name' in inventor:\n",
    "                    name_data = inventor['inventor-name']\n",
    "                    if isinstance(name_data, dict) and 'name' in name_data:\n",
    "                        name = name_data['name'].get('$', name_data['name'].get('#text', str(name_data['name'])))\n",
    "                        if isinstance(name, str) and name not in inventors:\n",
    "                            inventors.append(name)\n",
    "    \n",
    "    # Extract priority claims\n",
    "    priority_data = find_recursive(ops_data, ['priority-claim'])\n",
    "    priorities = []\n",
    "    for priority_section in priority_data:\n",
    "        if isinstance(priority_section, list):\n",
    "            for priority in priority_section:\n",
    "                if isinstance(priority, dict) and 'document-id' in priority:\n",
    "                    doc_id = priority['document-id']\n",
    "                    if isinstance(doc_id, dict):\n",
    "                        country = doc_id.get('country', {}).get('$', '')\n",
    "                        number = doc_id.get('doc-number', {}).get('$', '')\n",
    "                        date = doc_id.get('date', {}).get('$', '')\n",
    "                        if country == 'DE' and number and date:\n",
    "                            priorities.append(f\"{country}{number}Â·{date}\")\n",
    "    \n",
    "    # Extract title\n",
    "    title_data = find_recursive(ops_data, ['invention-title'])\n",
    "    title = ''\n",
    "    for title_section in title_data:\n",
    "        if isinstance(title_section, list):\n",
    "            for title_item in title_section:\n",
    "                if isinstance(title_item, dict):\n",
    "                    # Prefer English title\n",
    "                    if title_item.get('@lang') == 'en':\n",
    "                        title = title_item.get('$', title_item.get('#text', ''))\n",
    "                        break\n",
    "                    elif not title:  # Fallback to first available\n",
    "                        title = title_item.get('$', title_item.get('#text', ''))\n",
    "    \n",
    "    # Extract IPC classifications\n",
    "    classification_data = find_recursive(ops_data, ['classification-ipc'])\n",
    "    ipc_classes = []\n",
    "    for class_section in classification_data:\n",
    "        if isinstance(class_section, list):\n",
    "            for classification in class_section:\n",
    "                if isinstance(classification, dict) and 'text' in classification:\n",
    "                    ipc_text = classification['text'].get('$', classification['text'].get('#text', ''))\n",
    "                    if ipc_text:\n",
    "                        # Clean up IPC formatting\n",
    "                        clean_ipc = re.sub(r'\\s+', '', ipc_text)\n",
    "                        if clean_ipc not in ipc_classes:\n",
    "                            ipc_classes.append(clean_ipc)\n",
    "    \n",
    "    return {\n",
    "        'applicants': applicants,\n",
    "        'inventors': inventors,\n",
    "        'german_priorities': priorities,\n",
    "        'title': title,\n",
    "        'ipc_classes': ipc_classes\n",
    "    }\n",
    "\n",
    "def categorize_applicants(applicants):\n",
    "    \"\"\"Categorize applicants as University or Industry/Other\"\"\"\n",
    "    university_terms = ['university', 'universitÃ¤t', 'technische', 'hochschule', 'college', 'institut']\n",
    "    categorized = []\n",
    "    \n",
    "    for applicant in applicants:\n",
    "        app_lower = applicant.lower()\n",
    "        if any(term in app_lower for term in university_terms):\n",
    "            categorized.append({'applicant': applicant, 'type': 'University'})\n",
    "        else:\n",
    "            categorized.append({'applicant': applicant, 'type': 'Industry/Other'})\n",
    "    \n",
    "    return categorized\n",
    "\n",
    "def normalize_filename(filename):\n",
    "    \"\"\"Create safe filename from university name\"\"\"\n",
    "    # Replace problematic characters\n",
    "    safe_name = re.sub(r'[<>:\"/\\\\|?*]', '_', filename)\n",
    "    safe_name = re.sub(r'\\s+', '_', safe_name)\n",
    "    safe_name = safe_name.strip('_')\n",
    "    return safe_name\n",
    "\n",
    "def generate_pdf_report(university_name, analysis_data, output_dir):\n",
    "    \"\"\"Generate professional PDF report - only if reportlab is available\"\"\"\n",
    "    if not PDF_AVAILABLE:\n",
    "        print(\"âš ï¸ PDF generation skipped - reportlab not installed\")\n",
    "        return None\n",
    "        \n",
    "    safe_name = normalize_filename(university_name)\n",
    "    pdf_path = f\"{output_dir}/{safe_name}_analysis_report.pdf\"\n",
    "    \n",
    "    doc = SimpleDocTemplate(pdf_path, pagesize=A4)\n",
    "    styles = getSampleStyleSheet()\n",
    "    story = []\n",
    "    \n",
    "    # Title\n",
    "    title_style = ParagraphStyle('CustomTitle', fontSize=16, spaceAfter=30, alignment=1, textColor=colors.darkblue)\n",
    "    story.append(Paragraph(f\"Patent Portfolio Analysis: {university_name}\", title_style))\n",
    "    story.append(Spacer(1, 20))\n",
    "    \n",
    "    # Executive Summary\n",
    "    story.append(Paragraph(\"Executive Summary\", styles['Heading2']))\n",
    "    summary_text = f\"\"\"\n",
    "    This report presents a comprehensive analysis of {university_name}'s patent portfolio based on EPO OPS data.\n",
    "    The analysis includes {len(analysis_data)} patents with complete bibliographic information,\n",
    "    industry collaboration mapping, and strategic insights for patent intelligence purposes.\n",
    "    \"\"\"\n",
    "    story.append(Paragraph(summary_text, styles['Normal']))\n",
    "    story.append(Spacer(1, 20))\n",
    "    \n",
    "    # Key Metrics\n",
    "    story.append(Paragraph(\"Key Metrics\", styles['Heading2']))\n",
    "    metrics_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Total Patents Analyzed', str(len(analysis_data))],\n",
    "        ['Data Source', 'EPO OPS API'],\n",
    "        ['Analysis Date', datetime.now().strftime('%Y-%m-%d')],\n",
    "        ['Methodology', 'Comprehensive bibliographic enrichment']\n",
    "    ]\n",
    "    \n",
    "    metrics_table = Table(metrics_data)\n",
    "    metrics_table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, 0), 12),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n",
    "        ('GRID', (0, 0), (-1, -1), 1, colors.black)\n",
    "    ]))\n",
    "    \n",
    "    story.append(metrics_table)\n",
    "    story.append(Spacer(1, 20))\n",
    "    \n",
    "    # Patent Sample\n",
    "    story.append(Paragraph(\"Representative Patent Sample\", styles['Heading2']))\n",
    "    for i, patent in enumerate(analysis_data[:5], 1):\n",
    "        story.append(Paragraph(f\"Patent {i}: {patent.get('ep_patent', 'N/A')}\", styles['Heading3']))\n",
    "        story.append(Paragraph(f\"Title: {patent.get('title', 'N/A')[:100]}...\", styles['Normal']))\n",
    "        story.append(Paragraph(f\"Filing Year: {patent.get('filing_year', 'N/A')}\", styles['Normal']))\n",
    "        story.append(Spacer(1, 10))\n",
    "    \n",
    "    doc.build(story)\n",
    "    return pdf_path\n",
    "\n",
    "def perform_university_analysis():\n",
    "    \"\"\"Main analysis function triggered by widget interaction\"\"\"\n",
    "    \n",
    "    # Check if analysis was requested\n",
    "    if 'SELECTED_UNIVERSITY' not in globals():\n",
    "        print(\"âš ï¸ Please select a university and configure analysis options first!\")\n",
    "        return\n",
    "    \n",
    "    university_name = SELECTED_UNIVERSITY\n",
    "    analysis_types = SELECTED_ANALYSES\n",
    "    max_patents = MAX_PATENTS\n",
    "    create_pdf = CREATE_PDF\n",
    "    \n",
    "    print(f\"ğŸš€ STARTING ANALYSIS FOR: {university_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ğŸ“Š Analysis types: {', '.join(analysis_types)}\")\n",
    "    print(f\"ğŸ“„ Patent limit: {max_patents}\")\n",
    "    print(f\"ğŸ• Started: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    # Load DeepTechFinder data - try multiple possible paths\n",
    "    df = None\n",
    "    data_paths = [\n",
    "        './data/EPO_DeepTechFinder_20250513_DE_Uni_Top100.csv',\n",
    "        '../data/EPO_DeepTechFinder_20250513_DE_Uni_Top100.csv',\n",
    "        './EPO_DeepTechFinder_20250513_DE_Uni_Top100.csv',\n",
    "        '/home/jovyan/mtc-patent-analytics/deeptechfinder/data/EPO_DeepTechFinder_20250513_DE_Uni_Top100.csv'\n",
    "    ]\n",
    "    \n",
    "    for path in data_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(path, encoding='latin-1')\n",
    "            print(f\"âœ… Data loaded from: {path}\")\n",
    "            break\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error loading from {path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if df is None:\n",
    "        print(\"âŒ DeepTechFinder data file not found in any expected location\")\n",
    "        print(\"ğŸ’¡ Expected locations:\")\n",
    "        for path in data_paths:\n",
    "            print(f\"   - {path}\")\n",
    "        return\n",
    "    \n",
    "    # Filter for selected university\n",
    "    university_patents = df[df['University'] == university_name].head(max_patents)\n",
    "    \n",
    "    if len(university_patents) == 0:\n",
    "        print(f\"âŒ No patents found for {university_name}\")\n",
    "        return\n",
    "        \n",
    "    print(f\"ğŸ“„ Found {len(university_patents)} patents for analysis\")\n",
    "    \n",
    "    # Initialize EPO OPS client\n",
    "    ops_client = EPOOPSClient()\n",
    "    if not ops_client.get_access_token():\n",
    "        print(\"âŒ Failed to authenticate with EPO OPS\")\n",
    "        return\n",
    "    \n",
    "    # Process patents\n",
    "    analysis_results = []\n",
    "    successful_retrievals = 0\n",
    "    \n",
    "    for idx, (_, patent) in enumerate(university_patents.iterrows(), 1):\n",
    "        ep_number = patent['Espacenet_link'].split('=')[-1] if 'espacenet' in patent['Espacenet_link'].lower() else None\n",
    "        \n",
    "        if not ep_number:\n",
    "            continue\n",
    "            \n",
    "        print(f\"ğŸ” Processing {idx}/{len(university_patents)}: {ep_number}\")\n",
    "        \n",
    "        # Get EPO OPS data using the working method\n",
    "        ops_data = ops_client.get_application_biblio(ep_number)\n",
    "        \n",
    "        if ops_data:\n",
    "            bibliographic_data = extract_bibliographic_data(ops_data)\n",
    "            \n",
    "            # Combine with original data\n",
    "            result = {\n",
    "                'ep_patent': ep_number,\n",
    "                'filing_year': patent['Filing_year'],\n",
    "                'patent_status': patent['Patent_status'],\n",
    "                'technical_field': patent['Technical_field'],\n",
    "                'title': bibliographic_data.get('title', patent['Application_title']),\n",
    "                'applicants': bibliographic_data.get('applicants', []),\n",
    "                'inventors': bibliographic_data.get('inventors', []),\n",
    "                'german_priorities': bibliographic_data.get('german_priorities', []),\n",
    "                'ipc_classes': bibliographic_data.get('ipc_classes', [])\n",
    "            }\n",
    "            \n",
    "            analysis_results.append(result)\n",
    "            successful_retrievals += 1\n",
    "            print(f\"âœ… Retrieved data for {ep_number}\")\n",
    "        else:\n",
    "            print(f\"âŒ Failed to retrieve data for {ep_number}\")\n",
    "        \n",
    "        # Rate limiting - EPO OPS requirement\n",
    "        time.sleep(2)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ANALYSIS COMPLETED\")\n",
    "    print(f\"âœ… Successfully processed: {successful_retrievals}/{len(university_patents)} patents\")\n",
    "    print(f\"ğŸ“ˆ Success rate: {successful_retrievals/len(university_patents)*100:.1f}%\")\n",
    "    \n",
    "    if successful_retrievals == 0:\n",
    "        print(\"âŒ No patent data retrieved. Analysis cannot continue.\")\n",
    "        return\n",
    "    \n",
    "    # Generate outputs based on selected analysis types\n",
    "    safe_name = normalize_filename(university_name)\n",
    "    output_dir = './output'\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Complete analysis\n",
    "    if 'complete' in analysis_types:\n",
    "        complete_df = pd.DataFrame(analysis_results)\n",
    "        complete_path = f\"{output_dir}/{safe_name}_complete_analysis.csv\"\n",
    "        complete_df.to_csv(complete_path, index=False)\n",
    "        print(f\"ğŸ“„ Complete analysis saved: {complete_path}\")\n",
    "    \n",
    "    # Applicant analysis\n",
    "    if 'collaboration' in analysis_types:\n",
    "        all_applicants = []\n",
    "        for result in analysis_results:\n",
    "            all_applicants.extend(result['applicants'])\n",
    "        \n",
    "        unique_applicants = list(set(all_applicants))\n",
    "        categorized_applicants = categorize_applicants(unique_applicants)\n",
    "        \n",
    "        applicants_df = pd.DataFrame(categorized_applicants)\n",
    "        applicants_path = f\"{output_dir}/{safe_name}_applicants.csv\"\n",
    "        applicants_df.to_csv(applicants_path, index=False)\n",
    "        print(f\"ğŸ‘¥ Applicant analysis saved: {applicants_path}\")\n",
    "        \n",
    "        # Display collaboration insights\n",
    "        university_count = len([a for a in categorized_applicants if a['type'] == 'University'])\n",
    "        industry_count = len([a for a in categorized_applicants if a['type'] == 'Industry/Other'])\n",
    "        \n",
    "        print(f\"\\nğŸ¤ COLLABORATION INSIGHTS:\")\n",
    "        print(f\"   ğŸ›ï¸ University entities: {university_count}\")\n",
    "        print(f\"   ğŸ­ Industry partners: {industry_count}\")\n",
    "        print(f\"   ğŸ“Š Collaboration rate: {len(analysis_results)} patents analyzed\")\n",
    "    \n",
    "    # Priority analysis\n",
    "    if 'priority' in analysis_types:\n",
    "        priority_patents = []\n",
    "        for result in analysis_results:\n",
    "            if result['german_priorities']:\n",
    "                for priority in result['german_priorities']:\n",
    "                    priority_patents.append({\n",
    "                        'ep_patent': result['ep_patent'],\n",
    "                        'german_priority': priority,\n",
    "                        'applicants': result['applicants']\n",
    "                    })\n",
    "        \n",
    "        if priority_patents:\n",
    "            priority_df = pd.DataFrame(priority_patents)\n",
    "            priority_path = f\"{output_dir}/{safe_name}_german_priorities.csv\"\n",
    "            priority_df.to_csv(priority_path, index=False)\n",
    "            print(f\"ğŸ‡©ğŸ‡ª Priority analysis saved: {priority_path}\")\n",
    "            \n",
    "            priority_rate = len(priority_patents) / len(analysis_results) * 100\n",
    "            print(f\"   ğŸ“ˆ German priority rate: {priority_rate:.1f}%\")\n",
    "        else:\n",
    "            print(\"   â„¹ï¸ No German priorities found in analyzed patents\")\n",
    "    \n",
    "    # Inventor analysis\n",
    "    if 'inventors' in analysis_types:\n",
    "        all_inventors = []\n",
    "        for result in analysis_results:\n",
    "            all_inventors.extend(result['inventors'])\n",
    "        \n",
    "        unique_inventors = list(set(all_inventors))\n",
    "        inventors_df = pd.DataFrame({'inventor': unique_inventors})\n",
    "        inventors_path = f\"{output_dir}/{safe_name}_inventors.csv\"\n",
    "        inventors_df.to_csv(inventors_path, index=False)\n",
    "        print(f\"ğŸ”¬ Inventor analysis saved: {inventors_path}\")\n",
    "        print(f\"   ğŸ‘¨â€ğŸ”¬ Unique inventors: {len(unique_inventors)}\")\n",
    "    \n",
    "    # Technology analysis\n",
    "    if 'technology' in analysis_types:\n",
    "        all_ipc = []\n",
    "        for result in analysis_results:\n",
    "            all_ipc.extend(result['ipc_classes'])\n",
    "        \n",
    "        if all_ipc:\n",
    "            unique_ipc = list(set(all_ipc))\n",
    "            print(f\"\\nğŸ”¬ TECHNOLOGY PORTFOLIO:\")\n",
    "            print(f\"   ğŸ“š IPC classifications: {len(unique_ipc)}\")\n",
    "            print(f\"   ğŸ¯ Top classes: {', '.join(unique_ipc[:5])}\")\n",
    "    \n",
    "    # Generate PDF report\n",
    "    if create_pdf and analysis_results and PDF_AVAILABLE:\n",
    "        try:\n",
    "            pdf_path = generate_pdf_report(university_name, analysis_results, output_dir)\n",
    "            if pdf_path:\n",
    "                print(f\"ğŸ“‹ PDF report generated: {pdf_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ PDF generation failed: {e}\")\n",
    "    elif create_pdf and not PDF_AVAILABLE:\n",
    "        print(\"âš ï¸ PDF generation requested but reportlab not installed\")\n",
    "        print(\"ğŸ’¡ To enable PDF reports: pip install reportlab\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ ANALYSIS SUMMARY FOR {university_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"âœ… Patents processed: {successful_retrievals}\")\n",
    "    print(f\"ğŸ“Š Data quality: {successful_retrievals/len(university_patents)*100:.1f}% retrieval success\")\n",
    "    print(f\"ğŸ• Completed: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    print(f\"ğŸ“ All results saved to: {output_dir}/\")\n",
    "    \n",
    "    if successful_retrievals > 0:\n",
    "        print(f\"\\nğŸ’¡ Ready for further analysis with complete bibliographic data!\")\n",
    "        print(f\"ğŸ” Methodology validated and scalable to full portfolio\")\n",
    "\n",
    "# Check if analysis was requested and run it\n",
    "if 'SELECTED_UNIVERSITY' in globals():\n",
    "    perform_university_analysis()\n",
    "else:\n",
    "    print(\"âœ… EPO OPS Analysis Module Loaded\")\n",
    "    print(\"ğŸ“‹ Configure analysis options above and click 'Start Analysis' to proceed\")\n",
    "    print(\"ğŸ”§ All analysis functions ready for execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
